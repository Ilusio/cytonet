{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide as op\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import util\n",
    "import h5py\n",
    "from scipy import misc, ndimage\n",
    "from skimage import morphology\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addBackground(imArray, maskArray):\n",
    "    \"\"\"\n",
    "        Find the background on the array and put the value 2 on the mask\n",
    "    \"\"\"\n",
    "    green = imArray[:,:,1]\n",
    "    indexes = np.where(green<200)\n",
    "    background = np.zeros(maskArray.shape)\n",
    "    for i in range(len(indexes[0])):\n",
    "        background[indexes[0][i],indexes[1][i]]=1\n",
    "    # Morphological operations\n",
    "    slem = morphology.disk(10)\n",
    "    background = morphology.closing(background,slem)\n",
    "    background = morphology.erosion(background,slem)\n",
    "    background = ndimage.morphology.binary_fill_holes(background)\n",
    "    # Change the original mask\n",
    "    backgroundIndex = np.where(background==0)\n",
    "    backArray = np.array(maskArray)\n",
    "    for i in range(len(backgroundIndex[0])):\n",
    "        backArray[backgroundIndex[0][i],backgroundIndex[1][i]]=2\n",
    "    return backArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractPatches(output,filename,maskname, save=False):\n",
    "   \"\"\"\n",
    "       Extract the patches for the given file and maskname\n",
    "   \"\"\"\n",
    "   global j\n",
    "   global data\n",
    "   global offset\n",
    "   # Opening the files\n",
    "   im = op.OpenSlide(filename)\n",
    "   imload = im.read_region((0,0), 1, im.level_dimensions[1])\n",
    "   mask = Image.open(maskname)\n",
    "   if(imload.size != mask.size):\n",
    "      mask = mask.resize(imload.size, Image.ANTIALIAS)\n",
    "   imArray = np.array(imload)\n",
    "   maskArray = np.array(mask)\n",
    "   halfPatch = patchSize//2\n",
    "\n",
    "   #Preprocess\n",
    "   #maskArray = addBackground(imArray, maskArray)\n",
    "   imArray = np.lib.pad(imArray, ((halfPatch, halfPatch), (halfPatch, halfPatch),(0,0)), 'reflect')\n",
    "   maskArrayPad = np.lib.pad(maskArray, ((halfPatch, halfPatch), (halfPatch, halfPatch)), 'reflect')\n",
    "   np.putmask(maskArrayPad, maskArrayPad==1, 255)\n",
    "   # Extraction\n",
    "   for key, val in classes.items():\n",
    "       indices = np.where(maskArray==val)\n",
    "       sample = random.sample(range(len(indices[0])), img_classes[key])\n",
    "       maskClass = np.array(maskArrayPad) #TODO : remove this ?           \n",
    "       for i in sample:\n",
    "           x=indices[0][i]\n",
    "           y=indices[1][i]\n",
    "           x2 = x+patchSize\n",
    "           y2 = y+patchSize\n",
    "           croppedIm = imArray[x:x2,y:y2,0:3]\n",
    "           croppedMask = maskClass[x:x2,y:y2]\n",
    "           imageName = output +  \"/image_\" + str(j) + \".png\"\n",
    "           imageNameMask = output  + \"/image_\" + str(j) +\"_mask.png\"\n",
    "           # create the images if needed\n",
    "           if(save):\n",
    "               misc.imsave(imageName,croppedIm)\n",
    "               misc.imsave(imageNameMask,croppedMask)\n",
    "               os.chmod(imageName , 0o777)\n",
    "               os.chmod(imageNameMask, 0o777)\n",
    "           # concatenate to the arrays\n",
    "           data[key + '_imgs'][offset[key],:,:,:]=croppedIm.astype(np.float32)/255\n",
    "           data[key + '_masks'][offset[key],:,:,:]=np.expand_dims(croppedMask,-1).astype(np.float32)/255\n",
    "           offset[key] += 1\n",
    "           j+=1\n",
    "           if(j%100==0):\n",
    "               print(\"\",j,\" patches extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFiles(files, outputFolder, save=False):\n",
    "    \"\"\"\n",
    "        Extract all the files of a folder\n",
    "    \"\"\"\n",
    "    global data\n",
    "    global offset\n",
    "    n_files = len(files)\n",
    "    j = 0\n",
    "    #initialize arrays\n",
    "    for key, val in img_classes.items():\n",
    "        data[key] = {}\n",
    "        offset[key] = 0\n",
    "        data[key + '_imgs'] = np.zeros((n_files*val,patchSize,patchSize,3)).astype(np.float32)\n",
    "        data[key + '_masks'] = np.zeros((n_files*val,patchSize,patchSize, 1)).astype(np.float32)\n",
    "    for oneFile in files:\n",
    "        name = os.path.splitext(os.path.basename(oneFile))[0]\n",
    "        for key, val in classes.items():\n",
    "            folder = outputFolder\n",
    "            if not os.path.exists(folder):\n",
    "                try:\n",
    "                  original_umask = os.umask(0)\n",
    "                  os.makedirs(folder,0o777)\n",
    "                finally:\n",
    "                  os.umask(original_umask)\n",
    "        print(\"Extracting \" + name)\n",
    "        maskFile = glob.glob(os.path.dirname(oneFile)+\"/\"+name+maskPattern)[0]\n",
    "        extractPatches(outputFolder, oneFile,maskFile, save)\n",
    "        print(\"Extraction for \", name, \" finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeAndSave(outputFile):\n",
    "    \"\"\"\n",
    "        Normalize the data and save it in a file\n",
    "    \"\"\"\n",
    "    global data\n",
    "    all_data = np.zeros((j,patchSize,patchSize,3))\n",
    "    i = 0\n",
    "    # concatenate all the classes in one array to get the mean and std\n",
    "    for key, val in img_classes.items():\n",
    "        n = data[key+\"_imgs\"].shape[0] + i \n",
    "        all_data[i:n,:,:,:]= data[key+\"_imgs\"]\n",
    "        i += n\n",
    "    mean = all_data.mean()\n",
    "    std = all_data.std()\n",
    "    stats = np.zeros(2)\n",
    "    stats[0] = mean\n",
    "    stats[1] = std\n",
    "    # Normalize the data\n",
    "    for key, val in img_classes.items():\n",
    "        data[key+\"_imgs\"] -= mean\n",
    "        data[key+\"_imgs\"] /= std\n",
    "    print(\"Mean : \", stats[0])\n",
    "    print(\"Std : \", stats[1])\n",
    "    # Create the file\n",
    "    f = h5py.File(outputFile,\"w\")\n",
    "    f.create_dataset(\"stats\", data=stats)\n",
    "    for key, val in classes.items():\n",
    "        f.create_dataset(key+\"_imgs\", data=data[key+\"_imgs\"])\n",
    "        f.create_dataset(key+\"_masks\", data=data[key+\"_masks\"])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patchSize = 256 # Size of the patches\n",
    "filenames_train = ['/root/workspace/data/SVS_train/*.svs'] # Files we will extract for training. You can use pattern suchs as *.svs\n",
    "outputFolder_train = '/root/workspace/data/' # Output folder for training\n",
    "maskPattern= '*.png' # Pattern for the maskfilesoutputFile,\n",
    "classes = {'neg': 0, 'pos' : 1} # Classes and their value\n",
    "img_classes = {'neg' : 50 , 'pos' : 200} # Number of patches to extract for each class\n",
    "save = False # if true the images will be save\n",
    "j=0 # Counting variable\n",
    "data = {} # Dict with all data\n",
    "offset = {} # Dict with the offset per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the files for training\n",
    "files_train = []\n",
    "for filename in filenames_train:\n",
    "    files_train.extend(glob.glob(filename))\n",
    "print(files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training extraction\n",
    "extractFiles(files_train,outputFolder_train, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save the data\n",
    "normalizeAndSave(outputFolder_train+\"matrice_train.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
