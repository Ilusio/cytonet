{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from skimage import morphology, io, color, exposure, img_as_float, transform\n",
    "from matplotlib import pyplot as plt\n",
    "import openslide as op\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import configparser\n",
    "import ast\n",
    "from util import mkdirs, extend_glob, file_suffix, remove_small_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = configparser.RawConfigParser(interpolation=configparser.ExtendedInterpolation())\n",
    "config.read('cytonet.cfg')\n",
    "section = 'segmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "filenames = ast.literal_eval(config.get(section, 'filenames'))\n",
    "mask_pattern = config.get(section, 'mask_pattern')\n",
    "matrice_file = h5py.File(config.get(section, 'matrice_file') if config.has_option(section, 'matrice_file') \\\n",
    "                         else config.get('saving', 'output_file'),'r')\n",
    "output_pattern= config.get(section, 'output_pattern')\n",
    "\n",
    "experiment_folder = config.get(section, 'experiment_folder') if config.has_option(section, 'experiment_folder') \\\n",
    "                    else config.get('general', 'experiment_folder')\n",
    "model_name = os.path.join(experiment_folder,  \"matrices/\" , 'model.099.hdf5')\n",
    "\n",
    "load_level=config.getint(section, 'load_level') if config.has_option(section, 'load_level') else config.getint('general', 'load_level')\n",
    "patch_size = config.getint(section, 'patch_size') if config.has_option(section, 'patch_size') else config.getint('general', 'patch_size')\n",
    "stride = eval(config.get(section, 'stride'))\n",
    "\n",
    "color_channels = config.getint(section, 'color_channels') if config.has_option(section, 'color_channels') \\\n",
    "                else config.getint('general', 'color_channels')\n",
    "\n",
    "patch_shape = (patch_size, patch_size,color_channels) # Shape of the image (patch)\n",
    "patch_mask_shape = (patch_size, patch_size)   # Shape of the mask (patch)\n",
    "threshold = config.getfloat(section, 'threshold') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = extend_glob(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to find a proper way to do this\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.backend.common import _EPSILON\n",
    "import tensorflow as tf\n",
    "\n",
    "def _to_tensor(x, dtype):\n",
    "    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n",
    "    # Arguments\n",
    "        x: An object to be converted (numpy array, list, tensors).\n",
    "        dtype: The destination type.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    if x.dtype != dtype:\n",
    "        x = tf.cast(x, dtype)\n",
    "    return x\n",
    "\n",
    "def binary_crossentropy2K(output, target, from_logits=False):\n",
    "    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n",
    "    # Arguments\n",
    "        output: A tensor.\n",
    "        target: A tensor with the same shape as `output`.\n",
    "        from_logits: Whether `output` is expected to be a logits tensor.\n",
    "            By default, we consider that `output`\n",
    "            encodes a probability distribution.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n",
    "    # expects logits, Keras expects probabilities.\n",
    "    if not from_logits:\n",
    "        # transform back to logits\n",
    "        epsilon = _to_tensor(_EPSILON, output.dtype.base_dtype)\n",
    "        output = tf.clip_by_value(output, epsilon, 1 - epsilon)\n",
    "        output = tf.log(output / (1 - output))\n",
    "\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n",
    "                                                   logits=output)\n",
    "\n",
    "def binary_crossentropy2(y_true, y_pred):\n",
    "    #print(\"test:\")\n",
    "    #print(binary_crossentropy2K(y_pred, y_true))\n",
    "    #print(K.mean(binary_crossentropy2K(y_pred, y_true), axis=-1))\n",
    "    #print(\"test2:\")\n",
    "    return binary_crossentropy2K(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "keras.losses.binary_crossentropy2 = binary_crossentropy2\n",
    "#Another way to load the custom loss\n",
    "#model = load_model('model/multi_task/try.h5', custom_objects={'loss_max': loss_max})\n",
    "\n",
    "# Load model\n",
    "UNet = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading base picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    output_folder = os.path.join(experiment_folder, \"prediction\", os.path.splitext(os.path.basename(file))[0])\n",
    "    output_folder_jet = os.path.join(output_folder,\"proba\", \"jet\")\n",
    "    output_folder_gray = os.path.join(output_folder,\"proba\", \"grayscale\")\n",
    "    mkdirs(output_folder, 0o777)\n",
    "    mkdirs(output_folder_jet, 0o777)\n",
    "    mkdirs(output_folder_gray, 0o777)\n",
    "    \n",
    "    maskname = file_suffix(file, mask_pattern)\n",
    "    im = op.OpenSlide(file)\n",
    "    imload = np.asfarray(im.read_region((0,0), load_level, im.level_dimensions[load_level]),dtype=np.float32)[:,:,0:color_channels]/255\n",
    "    \n",
    "    if use_training_norm:\n",
    "        stats = matrice_file['stats'][:]\n",
    "        im_mean=stats[0]\n",
    "        im_std=stats[1]\n",
    "        matrice_file.close()\n",
    "\n",
    "        imload-=im_mean\n",
    "        imload/=im_std\n",
    "    else:\n",
    "        imload-=imload.mean()\n",
    "        imload/=imload.std()\n",
    "\n",
    "    maskload = Image.open(maskname)\n",
    "    maskload = np.expand_dims(np.array(maskload.resize(im.level_dimensions[load_level]),dtype=np.float32),-1)\n",
    "\n",
    "    outputProba = np.zeros((im.level_dimensions[load_level][1],im.level_dimensions[load_level][0],nb_classes),dtype=np.float32)\n",
    "    outputProbaTimes = np.zeros((im.level_dimensions[load_level][1],im.level_dimensions[load_level][0]),dtype=np.uint8)\n",
    "\n",
    "    # Prediction\n",
    "    for pos_x in range(0,im.level_dimensions[level][0],stride):\n",
    "        offset_x = pos_x+patch_size\n",
    "        for pos_y in range(0,im.level_dimensions[level][1],stride):\n",
    "            offset_y = pos_y+patch_size\n",
    "\n",
    "\n",
    "            if im.level_dimensions[level][1] < offset_y:\n",
    "                pos_y = im.level_dimensions[level][1]-patch_size\n",
    "                offset_y = pos_y+patch_size\n",
    "\n",
    "\n",
    "            if im.level_dimensions[level][0] < offset_x:\n",
    "                pos_x = im.level_dimensions[level][0]-patch_size\n",
    "                offset_x = pos_x+patch_size\n",
    "\n",
    "            xx = np.expand_dims(imload[pos_y:offset_y ,pos_x:offset_x,:],0)\n",
    "            yy = maskload[pos_y:offset_y,pos_x:offset_x,:]\n",
    "\n",
    "            #pred = UNet.predict(xx)[..., 1].reshape(patchShape[:2])\n",
    "            pred = UNet.predict(xx)[0,:,:,:]\n",
    "\n",
    "            part=output_proba[pos_y:offset_y,pos_x:offset_x]       # Creating a pointer on the area we just predicted\n",
    "            part[:,:]+=pred[0:part.shape[0],0:part.shape[1]]       # Filling the pointer with the information gathered from the prediction\n",
    "            output_proba_times[pos_y:offset_y,pos_x:offset_x]+=1    # Counting the amount of patches applying on every single pixel \n",
    "\n",
    "    t = time.clock()\n",
    "    print(\"Execution duration : \", t-t0)\n",
    "\n",
    "    #TODO: automate this, depending on the number of classes\n",
    "    \n",
    "    #Dividing pixels' values by the number of times the patch passed on it \n",
    "    output_proba[:,:,0]/=output_proba_times\n",
    "    output_proba[:,:,1]/=output_proba_times\n",
    "    output_proba[:,:,2]/=output_proba_times\n",
    "    \n",
    "    \n",
    "    output_proba1 = output_proba[:,:,0]\n",
    "    output_proba2 = output_proba[:,:,1]\n",
    "    output_proba3 = output_proba[:,:,2]\n",
    "    \n",
    "    if show_prediction:\n",
    "        plt.figure(figsize = (20,20)) # create a 5 x 5 figure *\n",
    "        plt.subplot(211)\n",
    "        plt.imshow(output_proba1,interpolation='none', cmap=\"jet\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize = (20,20)) # create a 5 x 5 figure *\n",
    "        plt.subplot(211)\n",
    "        plt.imshow(output_proba2,interpolation='none', cmap=\"jet\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize = (20,20)) # create a 5 x 5 figure *\n",
    "        plt.subplot(211)\n",
    "        plt.imshow(output_proba3,interpolation='none', cmap=\"jet\")\n",
    "        plt.show()\n",
    "    \n",
    "    #Saving probabilities\n",
    "    misc.imsave(os.path.join(output_folder_gray, \"proba1_gray.png\"), output_proba1)\n",
    "    misc.imsave(os.path.join(output_folder_gray, \"proba2_gray.png\"), output_proba2)\n",
    "    misc.imsave(os.path.join(output_folder_gray, \"proba3_gray.png\"), output_proba3)\n",
    "    \n",
    "    plt.imsave(os.path.join(output_folder_jet, \"proba1.png\"), output_proba1, cmap=plt.cm.jet)\n",
    "    plt.imsave(os.path.join(output_folder_jet, \"proba2.png\"), output_proba2, cmap=plt.cm.jet)\n",
    "    plt.imsave(os.path.join(output_folder_jet, \"proba3.png\"), output_proba3, cmap=plt.cm.jet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
